{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Dog Breed Prediction\n"
      ],
      "metadata": {
        "id": "IBnL0bmqGFx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  In this project, we will see how to use Keras and tensorflow to build, train, and test a Convolutional Neural Network capable of identifying the breed of a dog in a supplied image. This is a supervised learning problem, specifically for a multiclass classification problem."
      ],
      "metadata": {
        "id": "AevkYWkWGDDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to connect google colab with kaggle, download the kaggle.json file from kaggle and upload it here\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "_q0E-hVeGoFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install the kaggle API client\n",
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "7FbxWAARHvGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Kaggle API client expects this file to be in ~/. kaggle, so move it there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "abmxMG4vH-fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These step were to setup the kaggle api"
      ],
      "metadata": {
        "id": "r8CNY23DIvMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a new working directory to store the data , and make this as working directory\n",
        "!mkdir dog_dataset\n",
        "%cd dog_dataset"
      ],
      "metadata": {
        "id": "6ftFJxnFIz2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Next step : to search the Kaggle for the required data set in order to store the datas\n",
        "!kaggle datasets list -s dogbreedidfromcomp"
      ],
      "metadata": {
        "id": "eYdV4ZTIJHJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above step is to search the Kaggle for the required dataset using search option(-s) with title 'dogbreedidfromcomp'. We can also use different search options like searching competitions, notebooks, kernels, datasets, etc."
      ],
      "metadata": {
        "id": "1z5IYh1_JtF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we will download this data from kaggle dataset\n",
        "# Downloading dataset and coming out of directory\n",
        "!kaggle datasets download catherinehorng/dogbreedidfromcomp\n",
        "%cd .."
      ],
      "metadata": {
        "id": "Nps34sGjJdfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Un zip the downloaded data, remove the unusable files\n",
        "!unzip dog_dataset/dogbreedidfromcomp.zip -d dog_dataset\n",
        "!rm dog_dataset/dogbreedidfromcomp.zip\n",
        "!rm dog_dataset/sample_submission.csv"
      ],
      "metadata": {
        "id": "twWBbzlFKlwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the data is prepared, let's start building the model\n",
        "# important librabry imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing import image\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "C_akiRx3K7RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Next step : loading the labels data into the dataframe and view it\n",
        "# read the labels.csv file and check the shape and records\n",
        "labels_all = pd.read_csv('dog_dataset/labels.csv')\n",
        "print(labels_all.shape)\n",
        "labels_all.head()"
      ],
      "metadata": {
        "id": "-k9Dv66jLpzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the labels data into dataframe and viewing it. Analysed that labels contains 10222 rows and 2 columns"
      ],
      "metadata": {
        "id": "JYMsBD2AMUVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the number of each breeds\n",
        "breeds_all = labels_all['breed']\n",
        "breed_counts = breeds_all.value_counts()\n",
        "breed_counts.head()\n"
      ],
      "metadata": {
        "id": "haKOkSr6MjGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are finding out the count per class i.e. the total data in each class using value_counts() function"
      ],
      "metadata": {
        "id": "CHJPqU69NxNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting first 3 breeds ( limitation due to computation power)\n",
        "CLASS_NAMES = ['scottish_deerhound', 'maltese_dog', 'bernese_mountain_dog']\n",
        "labels = labels_all[labels_all['breed'].isin(CLASS_NAMES)]\n",
        "labels = labels.reset_index()\n",
        "labels.head()"
      ],
      "metadata": {
        "id": "VqCFJ3RrNaJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we are working with the classification dataset first we need to one hot encode the target value i.e. the classes. After that we will read images and convert them into numpy array and finally normalize the array"
      ],
      "metadata": {
        "id": "5AbGo16eO_cc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HyFG1xTFO5m2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the numpy matrix with zeros\n",
        "X_data = np.zeros((len(labels), 224, 224, 3), dtype='float32')\n",
        "# One hot encoding\n",
        "Y_data = label_binarize(labels['breed'], classes = CLASS_NAMES)\n",
        "\n",
        "# reading and converting image into numpy array and normalize the data set\n",
        "\n",
        "for i in tqdm(range(len(labels))):\n",
        "    img = image.load_img('dog_dataset/train/%s.jpg' % labels['id'][i], target_size=(224, 224))\n",
        "    img = image.img_to_array(img)\n",
        "    x = np.expand_dims(img.copy(), axis=0)\n",
        "    X_data[i] = x / 255.\n",
        "\n",
        "# Printing train image and one hot encode shape and size\n",
        "print('Train Images shape: ',X_data.shape, 'size : {:,}'.format(X_data.size))\n",
        "print('One hot encoded output shape:',Y_data.shape, 'size : {:,}'.format(Y_data.size))"
      ],
      "metadata": {
        "id": "ILt9BTDDPWZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "model = Sequential()  # considering the sequential model\n",
        "\n",
        "# Conv2d, maxpool2d flatten are the layers for this model. Playing with the hyperparameters\n",
        "# 1st layer = conv2d layer\n",
        "model.add(Conv2D(filters = 64, kernel_size = (5, 5), activation='relu', input_shape = (224,224,3)))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu', kernel_regularizer = 'l2'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "# MaxPool layer finds out the most prominant features in the 2x2 matrix\n",
        "\n",
        "model.add(Conv2D(filters = 16, kernel_size = (7, 7), activation='relu', kernel_regularizer = 'l2'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters = 8, kernel_size = (5, 5), activation='relu', kernel_regularizer = 'l2'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "# After setting up the layers, we will flatten the data as we need to apply the dense layer\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_regularizer = 'l2'))\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer = 'l2'))\n",
        "model.add(Dense(len(CLASS_NAMES), activation='softmax'))\n",
        "\n",
        "# softmax gives the probability of classes. So in a multiclass classification problem we generally\n",
        "# takes softmax as the activation function.\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.0001), metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "WQbUceUqQfuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the above step was to create the network architecture for the model. Different types of layers according to their features namely Conv_2d (used to convolutional kernel that is convolved with the input layer to produce the output sensor) , max_pooling2d (it is a down sampling technique which takes out maximum value over the window defined by pool size), flatten( it flattens the input and creates the 1D output), Dense (Dense layer produce the output as  the dot product of the input and the kernel)."
      ],
      "metadata": {
        "id": "6uv0cbSRTbD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into training and testing data sets\n",
        "X_train_and_val, X_test, Y_train_and_val, Y_test = train_test_split(X_data, Y_data, test_size = 0.1)\n",
        "# Splitting the training data into training and validation data sets\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train_and_val, Y_train_and_val, test_size = 0.2)"
      ],
      "metadata": {
        "id": "Y8xhF3HuTMMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taining the model / fit our model\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 128\n",
        "\n",
        "history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, validation_data = (X_val, Y_val))"
      ],
      "metadata": {
        "id": "yN-pNXvTUrRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training the model on 100 epochs and batch size of 128, can try using more number of epochs to increase the accuracy. During each epochs we can see how the model is performing by viewing the training and validation accuracy"
      ],
      "metadata": {
        "id": "pesuHniDVBeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training history\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.plot(history.history['accuracy'], color ='r')\n",
        "plt.plot(history.history['val_accuracy'], color='b')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jT26PPvJVVfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting activity by the model\n",
        "Y_pred = model.predict(X_test)\n",
        "score = model.evaluate(X_test, Y_test)\n",
        "print('Accuracy over the test set: \\n ', round((score[1]*100), 2), '%')"
      ],
      "metadata": {
        "id": "pEH4sBqsElOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On changing the mnodel's hypermeters / hyperparameter tuning , we can achieve better accuracy"
      ],
      "metadata": {
        "id": "WlvFPd-YWjpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the image to compare\n",
        "plt.imshow(X_test[1, :, :, :])\n",
        "plt.show()\n",
        "\n",
        "# Finding the max value from prediction list and compareing original value vs predicted\n",
        "print(\"Originally : \",labels['breed'][np.argmax(Y_test[1])])\n",
        "print(\"Predicted : \",labels['breed'][np.argmax(Y_pred[1])])"
      ],
      "metadata": {
        "id": "wl-W4kidWV6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the model\n",
        "model.save('dog_breed_classification_model.h5') # h5 is the format for saving the model"
      ],
      "metadata": {
        "id": "UND2tF56XYR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_qxnemyyvewv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}